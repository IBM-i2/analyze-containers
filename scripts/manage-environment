#!/usr/bin/env bash
# i2, i2 Group, the i2 Group logo, and i2group.com are trademarks of N.Harris Computer Corporation.
# Â© N.Harris Computer Corporation (2022-2023)
#
# SPDX short identifier: MIT
# shellcheck disable=SC2034
set -e

if [[ -z "${ANALYZE_CONTAINERS_ROOT_DIR}" ]]; then
  echo "ANALYZE_CONTAINERS_ROOT_DIR variable is not set" >&2
  echo "This project should be run inside a VSCode Dev Container. For more information read, the Getting Started guide at https://i2group.github.io/analyze-containers/content/getting_started.html" >&2
  exit 1
fi

USAGE="""
Usage:
  manage-environment -t backup [-p <path>] [-i <config_name>] [-e <config_name>] [-b <backup_name>] [-y]
  manage-environment -t copy -p <path> [-i <config_name>] [-e <config_name>] [-y]
  manage-environment -t upgrade [-y]
  manage-environment -t update [-y]
  manage-environment -t link [-y]
  manage-environment -t stop [-y]
  manage-environment -t renew-certificates [-y]
  manage-environment -t clean [-i <config_name>] [-e <config_name>] [-y]
  manage-environment -t connectors [-i <connector_name>] [-e <connector_name>] [-y]
  manage-environment -t extensions [-i <extension_name>] [-e <extension_name>] [-y]
  manage-environment -h

Options:
  -t {backup}                                                   Backup the database for a config.
  -t {copy}                                                     Copy the dependencies for a config from the specified path, to the current analyze-containers project.
  -t {upgrade}                                                  Upgrade all configurations from the specified path.
  -t {update}                                                   Update images.
  -t {link}                                                     Links shared configurations.
  -t {stop}                                                     Stops the running containers.
  -t {clean}                                                    Clean the deployment for a config. Will permanently remove all containers and data.
  -t {renew-certificates}                                            Renews the secrets for the configuration development environment.
  -t {connectors}                                               Build all connector images.
  -t {extensions}                                               Build all extensions.
  -i <config_name|extension_name|connector_name>                Name of the config, connector or extension to include for the task. To specify multiple values, add additional -i options.
  -e <config_name|extension_name|connector_name>                Name of the config, connector or extension to exclude for the task. To specify multiple values, add additional -e options.
  -b <backup_name>                                              Name of the backup to create or restore. If not specified, the default backup is used.
  -p <path>                                                     Path to the root of an analyze-containers project. Defaults to the current project path. Or $HOME/analyze-containers in upgrade.
  -y                                                            Answer 'yes' to all prompts.
  -v                                                            Verbose output.
  -h                                                            Display the help.
"""

source "${ANALYZE_CONTAINERS_ROOT_DIR}/utils/common_functions.sh"
OPTIONS_FOR="manageEnv"

function validate_arguments() {
  if [[ -z "${TASK}" ]]; then
    print_error_and_usage "Task is not set."
  fi

  [[ "${TASK}" == "backup" || "${TASK}" == "copy" || "${TASK}" == "upgrade" || "${TASK}" == "update" ||
    "${TASK}" == "connectors" || "${TASK}" == "extensions" || "${TASK}" == "clean" ||
    "${TASK}" == "stop" || "${TASK}" == "link" || "${TASK}" == "renew-certificates" ]] ||
    print_error_and_usage "${TASK} is not supported."

  if [[ "${TASK}" == "upgrade" ]]; then
    PREVIOUS_PROJECT_PATH="$(jq -r '.upgradeDirectory?' "${ANALYZE_CONTAINERS_ROOT_DIR}/path-configuration.json")"
    if [[ -z "${PREVIOUS_PROJECT_PATH}" || "${PREVIOUS_PROJECT_PATH}" == "null" ]]; then
      print_error_and_usage "upgradeDirectory not set in path-configuration.json"
    fi
  fi

  if [[ -z "${PREVIOUS_PROJECT_PATH}" ]]; then
    if [[ "${TASK}" == "copy" ]]; then
      print_error_and_usage "The path to an analyze-containers project must be set."
    fi
    PREVIOUS_PROJECT_PATH="${ANALYZE_CONTAINERS_ROOT_DIR}"
  elif [[ ! -d "${PREVIOUS_PROJECT_PATH}" ]]; then
    print_error_and_usage "Directory doesn't exist: ${PREVIOUS_PROJECT_PATH}"
  fi
  CURRENT_PROJECT_PATH="${ANALYZE_CONTAINERS_ROOT_DIR}"

  if [[ "${INCLUDED_ASSETS[*]}" && "${EXCLUDED_ASSETS[*]}" ]]; then
    print_error_and_usage "Incompatible options: Both (-i) and (-e) were specified."
  fi
}

function set_defaults() {
  if [[ -z "${BACKUP_NAME}" ]]; then
    if [[ "${TASK}" == "backup" ]]; then
      BACKUP_NAME="global-backup"
    else
      BACKUP_NAME="global-upgrade"
    fi
  fi
  if [[ "${TASK}" == "copy" || "${TASK}" == "backup" ]]; then
    CONTINUE_ON_ERROR="true"
  fi
}

function source_common_variables_and_scripts() {
  # The following should always be sourced again even when sourced before because of changes of ROOT_DIR
  # Load common functions
  source "${ANALYZE_CONTAINERS_ROOT_DIR}/utils/common_functions.sh"
  source "${ANALYZE_CONTAINERS_ROOT_DIR}/utils/client_functions.sh"

  # Load common variables
  source "${ANALYZE_CONTAINERS_ROOT_DIR}/utils/common_variables.sh"
  source "${ANALYZE_CONTAINERS_ROOT_DIR}/utils/simulated_external_variables.sh"
  source "${ANALYZE_CONTAINERS_ROOT_DIR}/utils/internal_helper_variables.sh"

  warn_root_dir_not_in_path
  if [[ "${TASK}" != "link" ]]; then
    set_dependencies_tag_if_necessary
  fi
}

function create_backup() {
  CONFIG_NAME="$1"

  check_valid_config_name "${CONFIG_NAME}" "${PREVIOUS_PROJECT_PATH}"

  print_info "Setting prerequisites to backup: ${CONFIG_NAME}"
  unset I2A_DEPENDENCIES_IMAGES_TAG

  # Needed for 2.1.3 and 2.2.0 upgrade
  AWS_DEPLOY="false"

  local client_function_paths=("${PREVIOUS_PROJECT_PATH}/utils/client_functions.sh" "${PREVIOUS_PROJECT_PATH}/utils/clientFunctions.sh")
  local common_variables_paths=("${PREVIOUS_PROJECT_PATH}/utils/common_variables.sh" "${PREVIOUS_PROJECT_PATH}/utils/commonVariables.sh")
  local simulated_variables_paths=("${PREVIOUS_PROJECT_PATH}/utils/simulated_external_variables.sh" "${PREVIOUS_PROJECT_PATH}/utils/simulatedExternalVariables.sh")
  local config_variables_paths=("${PREVIOUS_PROJECT_PATH}/configs/${CONFIG_NAME}/utils/variables.conf" "${PREVIOUS_PROJECT_PATH}/configs/${CONFIG_NAME}/utils/variables.sh")
  local version_paths=("${PREVIOUS_PROJECT_PATH}/configs/${CONFIG_NAME}/version.conf" "${PREVIOUS_PROJECT_PATH}/configs/${CONFIG_NAME}/version")
  local internal_variables_paths=("${PREVIOUS_PROJECT_PATH}/utils/internal_helper_variables.sh" "${PREVIOUS_PROJECT_PATH}/utils/internalHelperVariables.sh")
  if ! source "${PREVIOUS_PROJECT_PATH}/utils/common_functions.sh" >/dev/null 2>&1; then
    # shellcheck disable=SC1091
    source "${PREVIOUS_PROJECT_PATH}/utils/commonFunctions.sh"
  fi
  source_file_or_next client_function_paths
  source_file_or_next config_variables_paths
  source_file_or_next version_paths
  source_file_or_next simulated_variables_paths
  source_file_or_next common_variables_paths
  source_file_or_next internal_variables_paths

  # TODO: Remove on major version
  if [[ "${VERSION}" > "2.3.0" || "${VERSION}" == "2.3.0" ]]; then
    set_dependencies_tag_if_necessary
  fi

  if [[ "${VERSION}" < "2.6.1" ]]; then
    SQL_SERVER_IMAGE_VERSION="${I2A_DEPENDENCIES_IMAGES_TAG}"
  fi

  if [[ "${DEPLOYMENT_PATTERN}" != *"store"* ]]; then
    # Cannot print and exit since this is done for <all> configs and we want it to continue
    echo "${CONFIG_NAME} does not contain an ISTORE database to backup. It uses the ${DEPLOYMENT_PATTERN} deployment pattern."
    return
  fi

  print "Creating backup for: ${CONFIG_NAME}"
  local container_id

  case "${DB_DIALECT}" in
  db2)
    print_error_and_exit "Db2 backup in not implemented yet"
    return
    ;;
  sqlserver)
    container_id="$(docker ps -aq --no-trunc -f name="^${SQL_SERVER_CONTAINER_NAME}$")"
    container_name="SQL Server"
    ;;
  postgres)
    container_id="$(docker ps -aq --no-trunc -f name="^${POSTGRES_SERVER_CONTAINER_NAME}$")"
    container_name="Postgres"
    ;;
  esac

  if [[ -z "${container_id}" ]]; then
    print_error_and_exit "Cannot find the ${container_name} container for config: ${CONFIG_NAME}. Please redeploy before running this task again."
  fi

  # Restart Docker containers
  start_db_server

  if [[ -d "${PREVIOUS_PROJECT_PATH}/backups/${CONFIG_NAME}/${BACKUP_NAME}" ]]; then
    echo "There is already a backup for ${CONFIG_NAME} config with the name ${BACKUP_NAME}."
    if [[ "${TASK}" == "backup" ]]; then
      echo "You can run the command again and specify a different backup name by using the -b argument."
    fi
    wait_for_user_reply "Do you want to override the existing backup?"
  fi

  delete_folder_if_exists_and_create "${PREVIOUS_PROJECT_PATH}/backups/${CONFIG_NAME}/${BACKUP_NAME}"

  backup_database
  # shellcheck disable=SC2119
  stop_db_server
}

function create_backups() {
  for config_name in "${CONFIGS_ARRAY[@]}"; do
    create_backup "${config_name}"
  done
}

function build_plugins_array() {
  build_asset_array "plugin" "i2a-plugins"
}

function build_config_array() {
  build_asset_array "config" "configs"
}

function build_connectors_array() {
  build_asset_array "connector" "connector-images"
}

function build_extensions_array() {
  build_asset_array "extension" "i2a-extensions"
}

function run_backup_task() {
  stop_config_dev_containers
  stop_connector_containers

  export ANALYZE_CONTAINERS_ROOT_DIR="${PREVIOUS_PROJECT_PATH}"
  build_config_array
  create_backups
}

function copy_configurations() {
  print "Copying configs"

  if [[ -f "${PREVIOUS_PROJECT_PATH}/licenses.conf" ]]; then
    cp -pr "${PREVIOUS_PROJECT_PATH}/licenses.conf" "${CURRENT_PROJECT_PATH}/licenses.conf"
  fi

  if [[ -f "${PREVIOUS_PROJECT_PATH}/path-configuration.json" ]]; then
    cp "${PREVIOUS_PROJECT_PATH}/path-configuration.json" "${CURRENT_PROJECT_PATH}/path-configuration.json"
  fi

  local version_paths=("${PREVIOUS_PROJECT_PATH}/version.conf" "${PREVIOUS_PROJECT_PATH}/version")
  source_file_or_next version_paths

  delete_folder_if_exists_and_create "${PREVIOUS_PROJECT_PATH}/configs/.configs"
  delete_folder_if_exists_and_create "${CURRENT_PROJECT_PATH}/configs/.configs"

  for config_name in "${CONFIGS_ARRAY[@]}"; do
    check_valid_config_name "${config_name}" "${PREVIOUS_PROJECT_PATH}"
    local prev_config_path="${PREVIOUS_PROJECT_PATH}/configs/${config_name}"
    local current_config_path="${CURRENT_PROJECT_PATH}/configs/${config_name}"
    [[ ! -d "${prev_config_path}" ]] && continue
    if [[ -d "${current_config_path}" && ! -L "${current_config_path}" ]]; then
      print_error_and_exit "Config folder already exists: ${current_config_path}"
    else
      # Create a copy of the previous config
      cp -p -R -L "${prev_config_path}" "${PREVIOUS_PROJECT_PATH}/configs/.configs/${config_name}-previous"
      # Do not copy if the directory is a symlink
      if [[ ! -d "${current_config_path}" || ! -L "${prev_config_path}" ]]; then
        cp -pr "${prev_config_path}" "${CURRENT_PROJECT_PATH}/configs"
      fi
      # Rename to version.conf if required
      if [[ -f "${current_config_path}/version" && ! -f "${current_config_path}/version.conf" ]]; then
        mv "${current_config_path}/version" "${current_config_path}/version.conf"
      fi
      create_folder "${current_config_path}/configuration/web-dir-extensions"
      # Move privacyagreement if required
      if [[ -f "${current_config_path}/configuration/privacyagreement.html" ]]; then
        mv "${current_config_path}/configuration/privacyagreement.html" "${current_config_path}/configuration/web-dir-extensions/privacyagreement.html"
      fi

      # Ensure the version file is present and upgraded
      if [[ ! -f "${current_config_path}/version.conf" ]]; then
        cp "${CURRENT_PROJECT_PATH}/utils/templates/version.conf" "${current_config_path}"
        # TODO: Remove on major version
        if [[ "${VERSION}" < "2.3.0" ]]; then
          sed -i "s/^SUPPORTED_I2ANALYZE_VERSION=.*/SUPPORTED_I2ANALYZE_VERSION=${I2ANALYZE_VERSION}/g" "${current_config_path}/version.conf"
        else
          sed -i "s/^SUPPORTED_I2ANALYZE_VERSION=.*/SUPPORTED_I2ANALYZE_VERSION=${SUPPORTED_I2ANALYZE_VERSION}/g" "${current_config_path}/version.conf"
        fi
      else
        # Rename variable
        sed -i -r "s/^I2ANALYZE_VERSION=(.*)/SUPPORTED_I2ANALYZE_VERSION=\1/g" "${current_config_path}/version.conf"
      fi
      # Rename to .state.conf if required
      if [[ -f "${current_config_path}/.${config_name}/.state.sh" ]]; then
        mv "${current_config_path}/.${config_name}/.state.sh" "${current_config_path}/.${config_name}/.state.conf"
      fi
      # Add prometheus config
      if [[ ! -d "${current_config_path}/configuration/prometheus" ]]; then
        create_folder "${current_config_path}/configuration/prometheus"
        cp -pr "${CURRENT_PROJECT_PATH}/templates/config-development/configuration/prometheus/"* "${current_config_path}/configuration/prometheus"
      fi
      # Add grafana config
      if [[ ! -d "${current_config_path}/configuration/grafana" ]]; then
        create_folder "${current_config_path}/configuration/grafana"
        cp -pr "${CURRENT_PROJECT_PATH}/templates/config-development/configuration/grafana/"* "${current_config_path}/configuration/grafana"
      fi
      # Add privacy agreement
      if [[ ! -f "${current_config_path}/configuration/web-dir-extensions/privacyagreement.html" ]]; then
        cp -p "${CURRENT_PROJECT_PATH}/templates/config-development/configuration/web-dir-extensions/privacyagreement.html" "${current_config_path}/configuration/web-dir-extensions/privacyagreement.html"
      fi
      # Add properties file
      if [[ ! -f "${current_config_path}/configuration/InfoStoreNamesPostgres.properties" ]]; then
        cp -p "${CURRENT_PROJECT_PATH}/templates/config-development/configuration/InfoStoreNamesPostgres.properties" "${current_config_path}/configuration/InfoStoreNamesPostgres.properties"
      fi
      # TODO: Remove on major version
      # Rename variables.sh to variables.conf
      if [[ ! -f "${current_config_path}/utils/variables.conf" ]]; then
        if [[ -f "${current_config_path}/utils/variables.sh" ]]; then
          mv "${current_config_path}/utils/variables.sh" "${current_config_path}/utils/variables.conf"
        else
          cp -p "${CURRENT_PROJECT_PATH}/templates/config-development/configuration/utils/variables.conf" "${current_config_path}/utils/variables.conf"
        fi
      fi
      # Update HOST_PORT_PROMETHEUS to variables.sh
      if ! grep -q HOST_PORT_PROMETHEUS "${current_config_path}/utils/variables.conf"; then
        echo -e "\nHOST_PORT_PROMETHEUS=9090" >>"${current_config_path}/utils/variables.conf"
      fi
      # Update HOST_PORT_GRAFANA to variables.sh
      if ! grep -q HOST_PORT_GRAFANA "${current_config_path}/utils/variables.conf"; then
        echo -e "\nHOST_PORT_GRAFANA=3500" >>"${current_config_path}/utils/variables.conf"
      fi
    fi
    cp -p -R -L "${current_config_path}" "${CURRENT_PROJECT_PATH}/configs/.configs/${config_name}-current"
  done

  if [[ -d "${PREVIOUS_PROJECT_PATH}/examples/pre-prod/configuration" ]]; then
    if [[ ! -f "${PREVIOUS_PROJECT_PATH}/examples/pre-prod/configuration/version.conf" ]]; then
      cp "${CURRENT_PROJECT_PATH}/utils/templates/version.conf" "${PREVIOUS_PROJECT_PATH}/examples/pre-prod/configuration"
      # TODO: Remove on major version
      if [[ "${VERSION}" < "2.3.0" ]]; then
        sed -i "s/^SUPPORTED_I2ANALYZE_VERSION=.*/SUPPORTED_I2ANALYZE_VERSION=${I2ANALYZE_VERSION}/g" "${PREVIOUS_PROJECT_PATH}/examples/pre-prod/configuration/version.conf"
      else
        sed -i "s/^SUPPORTED_I2ANALYZE_VERSION=.*/SUPPORTED_I2ANALYZE_VERSION=${SUPPORTED_I2ANALYZE_VERSION}/g" "${PREVIOUS_PROJECT_PATH}/examples/pre-prod/configuration/version.conf"
      fi
    else
      # Rename variable
      sed -i -r "s/^I2ANALYZE_VERSION=(.*)/SUPPORTED_I2ANALYZE_VERSION=\1/g" "${PREVIOUS_PROJECT_PATH}/examples/pre-prod/configuration/version.conf"
    fi
  fi

  if [[ "${TASK}" == "upgrade" ]]; then
    local previous_pre_prod_config_path="${PREVIOUS_PROJECT_PATH}/examples/pre-prod/configuration"
    local current_pre_prod_config_path="${CURRENT_PROJECT_PATH}/examples/pre-prod/configuration"
    if [[ -d "${previous_pre_prod_config_path}" ]]; then
      delete_folder_if_exists_and_create "${current_pre_prod_config_path}"
      cp -pr "${previous_pre_prod_config_path}/"* "${current_pre_prod_config_path}"
      if [[ ! -f "${previous_pre_prod_config_path}/fragments/common/privacyagreement.html" ]]; then
        cp -p "${CURRENT_PROJECT_PATH}/pre-reqs/i2analyze/toolkit/examples/configurations/all-patterns/configuration/fragments/common/privacyagreement.html" "${current_pre_prod_config_path}/fragments/common/privacyagreement.html"
      fi
      if [[ ! -f "${previous_pre_prod_config_path}/fragments/opal-services-is/WEB-INF/classes/InfoStoreNamesPostgres.properties" ]]; then
        cp -p "${CURRENT_PROJECT_PATH}/pre-reqs/i2analyze/toolkit/examples/configurations/all-patterns/configuration/fragments/opal-services-is/WEB-INF/classes/InfoStoreNamesPostgres.properties" "${current_pre_prod_config_path}/fragments/opal-services-is/WEB-INF/classes/InfoStoreNamesPostgres.properties"
      fi
      if [[ -f "${current_pre_prod_config_path}/fragments/common/WEB-INF/classes/server.extensions.xml" ]]; then
        create_folder "${current_pre_prod_config_path}/liberty"
        mv "${current_pre_prod_config_path}/fragments/common/WEB-INF/classes/server.extensions.xml" "${current_pre_prod_config_path}/liberty/server.extensions.xml"
      fi
    fi
    local previous_pre_prod_generated_path="${PREVIOUS_PROJECT_PATH}/examples/pre-prod/database-scripts"
    local current_pre_prod_generated_path="${CURRENT_PROJECT_PATH}/examples/pre-prod/database-scripts"
    if [[ -d "${previous_pre_prod_generated_path}" ]]; then
      delete_folder_if_exists_and_create "${current_pre_prod_generated_path}"
      cp -pr "${previous_pre_prod_generated_path}/"* "${current_pre_prod_generated_path}"
    fi
  fi

  source "${CURRENT_PROJECT_PATH}/version.conf"
}

function copy_backups() {
  local backup_path backup_path_owner
  print "Copying backups"

  for backup_name in "${CONFIGS_ARRAY[@]}"; do
    backup_path="${PREVIOUS_PROJECT_PATH}/backups/${backup_name}"
    [[ ! -d "${backup_path}" || -L "${backup_path}" ]] && continue
    if [[ -d "${CURRENT_PROJECT_PATH}/backups/${backup_name}" ]]; then
      print_error_and_exit "Backup folder already exists: ${CURRENT_PROJECT_PATH}/backups/${backup_name}"
    else
      backup_path_owner="$(stat --format '%U' "${backup_path}")"
      if [[ "$USER" != "$backup_path_owner" ]]; then
        # Fix permissions
        sudo chown -R "$USER" "${backup_path}"
      fi
      cp -r "${backup_path}" "${CURRENT_PROJECT_PATH}/backups"
    fi
  done
}

function copy_extensions() {
  local extension_name
  print "Copying all extensions"

  for extension in "${PREVIOUS_PROJECT_PATH}"/i2a-extensions/*; do
    extension_name="$(basename "${extension}")"
    [[ ! -d "${extension}" || "${extension_name}" == "target" || -L "${extension}" ]] && continue
    if [[ -d "${CURRENT_PROJECT_PATH}/i2a-extensions/${extension_name}" ]]; then
      print_error_and_exit "Extension already exists: ${CURRENT_PROJECT_PATH}/i2a-extensions/${extension_name}"
    else
      cp -pr "${extension}" "${CURRENT_PROJECT_PATH}/i2a-extensions"
    fi
  done

  if [[ -f "${PREVIOUS_PROJECT_PATH}/i2a-extensions/extension-dependencies.json" ]]; then
    cp "${PREVIOUS_PROJECT_PATH}/i2a-extensions/extension-dependencies.json" "${CURRENT_PROJECT_PATH}/i2a-extensions/extension-dependencies.json"
  fi
}

function copy_plugins() {
  local plugin_name
  print "Copying all plugins"

  for plugin in "${PREVIOUS_PROJECT_PATH}"/i2a-plugins/*; do
    [[ ! -d "${plugin}" || -L "${plugin}" ]] && continue
    plugin_name=$(basename "${plugin}")
    if [[ -d "${CURRENT_PROJECT_PATH}/i2a-plugins/${plugin_name}" ]]; then
      print_error_and_exit "Plugin already exists: ${CURRENT_PROJECT_PATH}/i2a-plugins/${plugin_name}"
    else
      cp -pr "${plugin}" "${CURRENT_PROJECT_PATH}/i2a-plugins"
    fi
  done
}

function copy_secrets() {
  local old_secret_dir new_secret_dir secrets_owner
  print "Copying all secrets"

  secrets_owner="$(stat --format '%U' "${CURRENT_PROJECT_PATH}/dev-environment-secrets")"
  if [[ "$USER" != "$secrets_owner" ]]; then
    # Fix permissions
    sudo chown -R "$USER" "${CURRENT_PROJECT_PATH}/dev-environment-secrets"
  fi

  readarray -t secret_list < <(find "${PREVIOUS_PROJECT_PATH}/dev-environment-secrets" -mindepth 2 -maxdepth 2 -type d)
  for old_secret_dir in "${secret_list[@]}"; do
    new_secret_dir="${old_secret_dir/"${PREVIOUS_PROJECT_PATH}"/"${CURRENT_PROJECT_PATH}"}"
    if [ -z "$(ls -A "${old_secret_dir}")" ]; then
      continue # Ignore empty folders
    fi
    delete_folder_if_exists_and_create "${new_secret_dir}"
    cp -R "${old_secret_dir}"/* "${new_secret_dir}"
  done

  print_info "Generating missing secrets"
  "${ANALYZE_CONTAINERS_ROOT_DIR}/utils/scripts/generate-secrets"
}

function copy_connectors() {
  local connector_name
  print "Copying all connector images"

  for connector in "${PREVIOUS_PROJECT_PATH}"/connector-images/*; do
    [[ ! -d "${connector}" || -L "${connector}" ]] && continue
    connector_name=$(basename "${connector}")
    if [[ -d "${CURRENT_PROJECT_PATH}/connector-images/${connector_name}" ]]; then
      print_error_and_exit "Connector image folder already exists: ${CURRENT_PROJECT_PATH}/connector-images/${connector_name}"
    else
      cp -pr "${connector}" "${CURRENT_PROJECT_PATH}/connector-images"
    fi
  done
  if [[ -f "${PREVIOUS_PROJECT_PATH}/connector-images/i2connect-server-version.json" ]]; then
    cp "${PREVIOUS_PROJECT_PATH}/connector-images/i2connect-server-version.json" "${CURRENT_PROJECT_PATH}/connector-images/i2connect-server-version.json"
  fi
}

function copy_data() {
  local data_set_name
  print "Copying all data sets"

  for data_set in "${PREVIOUS_PROJECT_PATH}"/i2a-data/*; do
    [[ ! -d "${data_set}" || -L "${data_set}" ]] && continue
    data_set_name=$(basename "${data_set}")
    if [[ -d "${CURRENT_PROJECT_PATH}/i2a-data/${data_set_name}" ]]; then
      print_error_and_exit "Data set folder already exists: ${CURRENT_PROJECT_PATH}/i2a-data/${data_set_name}"
    else
      cp -pr "${data_set}" "${CURRENT_PROJECT_PATH}/i2a-data"
    fi
  done
}

function copy_gateway_schemas() {
  local gateway_schema_name
  print "Copying all gateway schemas"

  for gateway_schema in "${PREVIOUS_PROJECT_PATH}"/gateway-schemas/*; do
    [[ ! -f "${gateway_schema}" || -L "${gateway_schema}" ]] && continue
    gateway_schema_name=$(basename "${gateway_schema}")
    if [[ -f "${CURRENT_PROJECT_PATH}/gateway-schemas/${gateway_schema_name}" ]]; then
      print_error_and_exit "Gateway Schema already exists: ${CURRENT_PROJECT_PATH}/gateway-schemas/${gateway_schema_name}"
    else
      cp -pr "${gateway_schema}" "${CURRENT_PROJECT_PATH}/gateway-schemas/"
    fi
  done
}

function copy_additional_resources() {
  print "Copying all additional resources"

  for additional_resource in "${PREVIOUS_PROJECT_PATH}"/additional-resources/*; do
    [[ ! -d "${additional_resource}" || -L "${additional_resource}" ]] && continue
    additional_resource_name=$(basename "${additional_resource}")
    if [[ -d "${CURRENT_PROJECT_PATH}/additional-resources/${additional_resource_name}" ]]; then
      print_error_and_exit "Additional resource folder already exists: ${CURRENT_PROJECT_PATH}/additional-resources/${additional_resource_name}"
    else
      cp -pr "${additional_resource}" "${CURRENT_PROJECT_PATH}/additional-resources"
    fi
  done
}

function run_copy_task() {
  export ANALYZE_CONTAINERS_ROOT_DIR="${PREVIOUS_PROJECT_PATH}"
  build_config_array
  export ANALYZE_CONTAINERS_ROOT_DIR="${CURRENT_PROJECT_PATH}"
  copy_configurations
  copy_backups
  copy_extensions
  copy_plugins
  copy_connectors
  copy_gateway_schemas
  copy_data
  copy_additional_resources
  copy_secrets
}

function run_upgrade_task() {
  local same_version="false"
  export ANALYZE_CONTAINERS_ROOT_DIR="${PREVIOUS_PROJECT_PATH}"
  unset SUPPORTED_I2ANALYZE_VERSION
  local version_paths=("${PREVIOUS_PROJECT_PATH}/version.conf" "${PREVIOUS_PROJECT_PATH}/version")
  source_file_or_next version_paths
  OLD_SUPPORTED_I2ANALYZE_VERSION="${SUPPORTED_I2ANALYZE_VERSION}"
  if [[ -z "${OLD_SUPPORTED_I2ANALYZE_VERSION}" ]]; then
    OLD_SUPPORTED_I2ANALYZE_VERSION="${I2ANALYZE_VERSION%.*}"
  fi
  local deploy_script_name
  if [[ "${VERSION}" < "2.4.0" ]]; then
    deploy_script_name="deploy.sh"
  else
    deploy_script_name="deploy"
  fi
  local version_paths=("${CURRENT_PROJECT_PATH}/version.conf" "${CURRENT_PROJECT_PATH}/version")
  source_file_or_next version_paths

  if [[ "${OLD_SUPPORTED_I2ANALYZE_VERSION}" == "${SUPPORTED_I2ANALYZE_VERSION}" ]]; then
    same_version="true"
    wait_for_user_reply "This upgrade uses the same version of i2 Analyze. The process will upgrade your environment in ${PREVIOUS_PROJECT_PATH}. Do you want to continue?"
  fi

  # Prepare
  stop_config_dev_containers
  stop_connector_containers
  build_config_array

  # Backup all
  create_backups

  # Reset to correct root
  export ANALYZE_CONTAINERS_ROOT_DIR="${CURRENT_PROJECT_PATH}"
  unset I2A_DEPENDENCIES_IMAGES_TAG
  source_common_variables_and_scripts

  # Copy all
  copy_configurations
  copy_backups
  copy_extensions
  copy_plugins
  copy_connectors
  copy_gateway_schemas
  copy_data
  copy_secrets

  # The version is changed in the copy_configurations function when sourcing old one
  source "${ANALYZE_CONTAINERS_ROOT_DIR}/version.conf"

  # Upgrade
  extra_args=()
  if [[ "${YES_FLAG}" == "true" ]]; then
    extra_args+=("-y")
  fi
  if [[ "${VERBOSE}" == "true" ]]; then
    extra_args+=("-v")
  fi

  # Create an empty string to store the summary
  local summary=""

  for config_name in "${CONFIGS_ARRAY[@]}"; do
    local backup_upgraded="false"
    local config_summary=""

    stop_config_dev_containers
    stop_connector_containers

    if wait_for_user_reply "Do you want to upgrade all backups" "false"; then
      if [[ -d "${ANALYZE_CONTAINERS_ROOT_DIR}/backups/${config_name}" && -n $(ls -A "${ANALYZE_CONTAINERS_ROOT_DIR}/backups/${config_name}") ]]; then
        # Create an empty array to store folder names
        local backup_folders=()
        # Use the find command to retrieve directory names and populate the array
        while IFS= read -r -d '' folder; do
          backup_folders+=("${folder}")
        done < <(find "${ANALYZE_CONTAINERS_ROOT_DIR}/backups/${config_name}" -mindepth 1 -maxdepth 1 -type d -print0)
        # Iterate over each backup folder
        for backup in "${backup_folders[@]}"; do
          backup_name=$(basename "${backup}")
          if [[ "${backup_name}" == "global-upgrade" ]]; then
            continue
          fi
          # restore previous deployment to the <backup_name>
          rsync -aqprKl \
            --delete \
            "${PREVIOUS_PROJECT_PATH}/configs/.configs/${config_name}-previous/" \
            "${PREVIOUS_PROJECT_PATH}/configs/${config_name}"
          source_file_or_next version_paths
          unset I2A_DEPENDENCIES_IMAGES_TAG
          export ANALYZE_CONTAINERS_ROOT_DIR="${PREVIOUS_PROJECT_PATH}"
          "${PREVIOUS_PROJECT_PATH}/scripts/${deploy_script_name}" -c "${config_name}" -t restore -b "${backup_name}" "${extra_args[@]}"
          # upgrade previous deployment with the <backup_name>
          export ANALYZE_CONTAINERS_ROOT_DIR="${CURRENT_PROJECT_PATH}"
          rsync -aqprKl \
            --delete \
            "${CURRENT_PROJECT_PATH}/configs/.configs/${config_name}-current/" \
            "${CURRENT_PROJECT_PATH}/configs/${config_name}"
          source "${CURRENT_PROJECT_PATH}/version.conf"
          "${CURRENT_PROJECT_PATH}/scripts/deploy" -c "${config_name}" -b "${backup_name}" "${extra_args[@]}"
          "${CURRENT_PROJECT_PATH}/scripts/deploy" -c "${config_name}" -t backup -b "${backup_name}.tmp" "${extra_args[@]}"
          "${CURRENT_PROJECT_PATH}/scripts/deploy" -c "${config_name}" -t clean "${extra_args[@]}"
          # clean up
          delete_folder_if_exists "${backup}"
          mv "${backup}.tmp" "${backup}"
          backup_upgraded="true"
          config_summary+="  - \"${backup_name}\"\n"
        done

        # backup_upgraded could still be false
        # if there was no other backups other then 'global-upgrade'
        if [[ "${backup_upgraded}" == "true" ]]; then
          stop_config_dev_containers
          stop_connector_containers
          # delete change-sets generated for upgrading previous backups
          rsync -aqprKl \
            --delete \
            "${PREVIOUS_PROJECT_PATH}/configs/.configs/${config_name}-previous/" \
            "${PREVIOUS_PROJECT_PATH}/configs/${config_name}"
          # update variables to previous
          source_file_or_next version_paths
          unset I2A_DEPENDENCIES_IMAGES_TAG
          export ANALYZE_CONTAINERS_ROOT_DIR="${PREVIOUS_PROJECT_PATH}"
          # restore to global-upgrade
          "${PREVIOUS_PROJECT_PATH}/scripts/${deploy_script_name}" -c "${config_name}" -t restore -b "global-upgrade" "${extra_args[@]}"
          # update variables to current
          export ANALYZE_CONTAINERS_ROOT_DIR="${CURRENT_PROJECT_PATH}"
          source "${CURRENT_PROJECT_PATH}/version.conf"

          rsync -aqprKl \
            --delete \
            "${CURRENT_PROJECT_PATH}/configs/.configs/${config_name}-current/" \
            "${CURRENT_PROJECT_PATH}/configs/${config_name}"
        fi
      fi
    fi

    "${ANALYZE_CONTAINERS_ROOT_DIR}/scripts/deploy" -c "${config_name}" "${extra_args[@]}"
    summary+="---\n"
    summary+="Config \"${config_name}\" successfully upgraded.\n"
    if [[ "${backup_upgraded}" == "true" ]]; then
      summary+="Associated backups successfully upgraded:\n"
      summary+="${config_summary}"
    fi
  done

  "${ANALYZE_CONTAINERS_ROOT_DIR}/scripts/configure-paths" -t upgrade -d

  # Print the summary
  summary+="---\n"
  print "Upgrade summary"
  echo -e "${summary}"

  if [[ "${same_version}" == "false" ]]; then
    wait_for_user_reply "To replace the contents of ${PREVIOUS_PROJECT_PATH} with the upgraded version, enter 'y'. To continue working with ${PREVIOUS_PROJECT_PATH} and ${CURRENT_PROJECT_PATH} at the same time, enter 'n' and rebuild the Dev Container."
  fi

  # Delete all secrets first
  delete_folder_if_exists "${PREVIOUS_PROJECT_PATH}/dev-environment-secrets"
  # cspell:ignore aqprKl
  rsync -aqprKl --exclude='dev' --delete "${ANALYZE_CONTAINERS_ROOT_DIR}/" "${PREVIOUS_PROJECT_PATH}"

  echo "Please delete ${CURRENT_PROJECT_PATH} and open ${PREVIOUS_PROJECT_PATH} in a new VSCode window."
}

function get_image_id() {
  local image_name_and_version="$1"

  docker inspect --format "{{.Id}}" "${image_name_and_version}"
}

function get_base_image_ids() {
  local image_ids

  image_ids+=$(get_image_id "${JAVA_IMAGE_NAME}:${JAVA_IMAGE_VERSION}")
  image_ids+=$(get_image_id "${REDHAT_UBI_IMAGE_NAME}:${REDHAT_UBI_IMAGE_VERSION}")
  image_ids+=$(get_image_id "haproxy:${HA_PROXY_IMAGE_VERSION}")
  image_ids+=$(get_image_id "i2group/i2eng-liberty:${LIBERTY_VERSION}")
  image_ids+=$(get_image_id "i2group/i2eng-solr:${SOLR_VERSION}")
  image_ids+=$(get_image_id "${ZOOKEEPER_IMAGE_NAME}:${ZOOKEEPER_VERSION}")
  image_ids+=$(get_image_id "i2group/i2eng-prometheus:${PROMETHEUS_VERSION}")
  image_ids+=$(get_image_id "${GRAFANA_IMAGE_NAME}:${GRAFANA_VERSION}")
  image_ids+=$(get_image_id "${POSTGRES_SERVER_IMAGE_NAME}:${POSTGRES_IMAGE_VERSION}")
  image_ids+=$(get_image_id "${SQL_SERVER_IMAGE_NAME}:${SQL_SERVER_IMAGE_VERSION}")
  image_ids+=$(get_image_id "${NODEJS_IMAGE_NAME}:${NODEJS_IMAGE_VERSION}")
  image_ids+=$(get_image_id "${SPRINGBOOT_IMAGE_NAME}:${SPRINGBOOT_IMAGE_VERSION}")

  echo "${image_ids}"
}

function get_image_ids() {
  local image_ids

  image_ids+=$(get_image_id "${LOAD_BALANCER_IMAGE_NAME}:${I2A_DEPENDENCIES_IMAGES_TAG}")
  image_ids+=$(get_image_id "${LIBERTY_BASE_IMAGE_NAME}:${I2A_DEPENDENCIES_IMAGES_TAG}")
  image_ids+=$(get_image_id "${SOLR_IMAGE_NAME}:${I2A_DEPENDENCIES_IMAGES_TAG}")
  image_ids+=$(get_image_id "${SQL_CLIENT_IMAGE_NAME}:${I2A_DEPENDENCIES_IMAGES_TAG}")
  image_ids+=$(get_image_id "${POSTGRES_CLIENT_IMAGE_NAME}:${I2A_DEPENDENCIES_IMAGES_TAG}")
  image_ids+=$(get_image_id "${I2A_TOOLS_IMAGE_NAME}:${I2A_DEPENDENCIES_IMAGES_TAG}")

  if [[ "${DEV_DB2_BUILD}" == "true" ]]; then
    image_ids+=$(get_image_id "${DB2_CLIENT_IMAGE_NAME}:${I2A_DEPENDENCIES_IMAGES_TAG}")
    image_ids+=$(get_image_id "${DB2_SERVER_IMAGE_NAME}:${I2A_DEPENDENCIES_IMAGES_TAG}")
  fi

  echo "${image_ids}"
}

function run_update_task() {
  local previous_image_ids current_image_ids
  set_dependencies_tag_if_necessary

  # Check base images first
  previous_image_ids=$(get_base_image_ids)
  pull_base_images
  current_image_ids=$(get_base_image_ids)
  print_info "PREVIOUS_IMAGE_IDS: ${previous_image_ids}"
  print_info "CURRENT_IMAGE_IDS: ${current_image_ids}"
  if [[ "${previous_image_ids}" == "${current_image_ids}" ]]; then
    print "Your images are already up-to-date. You do NOT need to clean and redeploy your configs."
    return
  fi

  # Check next images
  previous_image_ids=$(get_image_ids)
  print "Running build-images"
  "${ANALYZE_CONTAINERS_ROOT_DIR}/utils/scripts/build-images"
  current_image_ids=$(get_image_ids)
  print_info "PREVIOUS_IMAGE_IDS: ${previous_image_ids}"
  print_info "CURRENT_IMAGE_IDS: ${current_image_ids}"
  if [[ "${previous_image_ids}" == "${current_image_ids}" ]]; then
    print "Your images are already up-to-date. You do NOT need to clean and redeploy your configs."
  else
    print "Your images have been updated. Use the deploy script to clean and redeploy your configs."
  fi
}

function clean_deployment() {
  CONFIG_NAME="$1"
  # shellcheck disable=SC1090
  source "${ANALYZE_CONTAINERS_ROOT_DIR}/configs/${CONFIG_NAME}/version.conf"
  # shellcheck disable=SC1090
  source "${ANALYZE_CONTAINERS_ROOT_DIR}/configs/${CONFIG_NAME}/utils/variables.conf"
  source "${ANALYZE_CONTAINERS_ROOT_DIR}/utils/common_variables.sh"
  source "${ANALYZE_CONTAINERS_ROOT_DIR}/utils/internal_helper_variables.sh"

  local all_container_ids
  IFS=' ' read -ra all_container_ids <<<"$(docker ps -aq -f network="${DOMAIN_NAME}" -f name="\.${CONFIG_NAME}_${CONTAINER_VERSION_SUFFIX}$" | xargs)"
  print "Deleting all containers for ${CONFIG_NAME} deployment"
  for container_id in "${all_container_ids[@]}"; do
    print_info "Deleting container ${container_id}"
    delete_container "${container_id}"
  done

  remove_docker_volumes

  print_info "Deleting previous configuration folder: ${PREVIOUS_CONFIGURATION_DIR}"
  delete_folder_if_exists "${PREVIOUS_CONFIGURATION_DIR}"
}

function run_clean_task() {
  wait_for_user_reply "Are you sure you want to run the 'clean' task? This will permanently remove data from the deployment."

  build_config_array
  for config_name in "${CONFIGS_ARRAY[@]}"; do
    clean_deployment "${config_name}"
  done

  # Reset assets since they are specific for configs only in this task
  INCLUDED_ASSETS=()
  EXCLUDED_ASSETS=()

  build_connectors_array
  for connector in "${CONNECTORS_ARRAY[@]}"; do
    delete_file_if_exists "${PREVIOUS_CONNECTOR_IMAGES_DIR}/${connector}.sha512"
  done

  build_extensions_array
  for extension in "${EXTENSIONS_ARRAY[@]}"; do
    delete_file_if_exists "${PREVIOUS_EXTENSIONS_DIR}/${extension}.sha512"
  done

  build_plugins_array
  for plugin_name in "${PLUGINS_ARRAY[@]}"; do
    delete_file_if_exists "${PREVIOUS_PLUGINS_DIR}/${plugin_name}.sha512"
  done

  echo "Done"
}

function run_stop_task() {
  wait_for_user_reply "Are you sure you want to run the 'stop' task? This will stop all containers running in the ${DOMAIN_NAME} network."

  local all_container_ids container_id
  IFS=' ' read -ra all_container_ids <<<"$(docker ps -q -f network="${DOMAIN_NAME}" | xargs)"
  print "Stopping all containers in the ${DOMAIN_NAME} network"
  for container_id in "${all_container_ids[@]}"; do
    [[ "${container_id}" == "${HOSTNAME}" ]] && continue # Skip dev container
    print_info "Stopping container ${container_id}"
    stop_container "${container_id}"
  done

  echo "Done"
}

function remove_all_volumes() {
  print "Removing all volumes"
  VOLUME_NAME_PREFIX=("zk" "solr" "sqlserver" "db2server" "liberty" "i2a_data" "load_balancer")

  for volume_prefix in "${VOLUME_NAME_PREFIX[@]}"; do
    readarray -t volumes < <(docker volume ls -q --filter "name=^${volume_prefix}" --format "{{.Name}}")
    if [[ "${#volumes[@]}" -ne 0 ]]; then
      docker volume rm "${volumes[@]}"
    fi
  done
}

function run_renew_certificates_task() {
  build_config_array
  for config_name in "${CONFIGS_ARRAY[@]}"; do
    source "${ANALYZE_CONTAINERS_ROOT_DIR}/configs/${config_name}/version.conf"
    source "${ANALYZE_CONTAINERS_ROOT_DIR}/configs/${config_name}/utils/variables.conf"
    source "${ANALYZE_CONTAINERS_ROOT_DIR}/utils/simulated_external_variables.sh"
    source "${ANALYZE_CONTAINERS_ROOT_DIR}/utils/common_variables.sh"
    source "${ANALYZE_CONTAINERS_ROOT_DIR}/utils/internal_helper_variables.sh"

    PREVIOUS_STATE_FILE_PATH="${ANALYZE_CONTAINERS_ROOT_DIR}/configs/${config_name}/.${config_name}/.state.conf"
    if [[ -f "${PREVIOUS_STATE_FILE_PATH}" ]]; then
      source "${PREVIOUS_STATE_FILE_PATH}"
      if [[ "${STATE}" -ge "3" ]]; then
        update_state_file 5
      fi
    fi
  done

  delete_all_containers "true"

  extra_args=()
  if [[ "${VERBOSE}" == "true" ]]; then
    extra_args+=("-v")
  fi
  if [[ "${YES_FLAG}" == "true" ]]; then
    extra_args+=("-y")
  fi

  print "Deleting old certificates"
  delete_folder_if_exists "${LOCAL_GENERATED_SECRETS_DIR}/certificates"
  delete_folder_if_exists "${LOCAL_KEYS_DIR}"
  print "Running generate-secrets"
  "${ANALYZE_CONTAINERS_ROOT_DIR}/utils/scripts/generate-secrets" "${extra_args[@]}"
}

function run_prune_task() {
  wait_for_user_reply "Are you sure you want to run the 'prune' task? This will permanently remove data and images from the deployment."

  for config in "${PREVIOUS_PROJECT_PATH}"/configs/*; do
    if [[ ! -d "${config}" ]]; then
      continue
    fi

    CONFIG_NAME=$(basename "${config}")
    source "${ANALYZE_CONTAINERS_ROOT_DIR}/utils/internal_helper_variables.sh"

    print_info "Deleting previous configuration folder: ${PREVIOUS_CONFIGURATION_DIR}"
    delete_folder_if_exists "${PREVIOUS_CONFIGURATION_DIR}"
  done

  delete_all_containers

  remove_all_volumes

  print "Removing all images"
  IMAGE_NAME_PREFIX=("zookeeper_" "solr_" "sqlserver_" "db2_" "liberty_" "etlclient_" "i2a_tools_" "ha_proxy_" "example_connector" "i2connect_sdk")

  for image_prefix in "${IMAGE_NAME_PREFIX[@]}"; do
    readarray -t images < <(docker image ls --filter "reference=${image_prefix}*" --format "{{.Repository}}:{{.Tag}}")
    if [[ "${#images[@]}" -ne 0 ]]; then
      docker rmi "${images[@]}"
    fi
  done
}

function run_build_connectors_task() {
  local connector_args=()

  build_connectors_array

  for connector in "${CONNECTORS_ARRAY[@]}"; do
    connector_args+=(-i "${connector}")
    delete_file_if_exists "${PREVIOUS_CONNECTOR_IMAGES_DIR}/${connector}.sha512"
  done

  if [[ "${YES_FLAG}" == "true" ]]; then
    connector_args+=("-y")
  fi

  if [[ "${VERBOSE}" == "true" ]]; then
    connector_args+=("-v")
  fi

  print "Running generate-secrets"
  "${ANALYZE_CONTAINERS_ROOT_DIR}/utils/scripts/generate-secrets" -c connectors "${connector_args[@]}"
  print "Running build-connector-images"
  "${ANALYZE_CONTAINERS_ROOT_DIR}/utils/scripts/build-connector-images" "${connector_args[@]}"

  print_success "Connectors have been built"
}

function run_build_extensions_task() {
  local extension_args=()

  build_extensions_array

  for extension in "${EXTENSIONS_ARRAY[@]}"; do
    extension_args+=(-i "${extension}")
    delete_file_if_exists "${PREVIOUS_EXTENSIONS_DIR}/${extension}.sha512"
  done

  if [[ "${YES_FLAG}" == "true" ]]; then
    extension_args+=("-y")
  fi

  if [[ "${VERBOSE}" == "true" ]]; then
    extension_args+=("-v")
  fi

  print "Building i2 Analyze extensions"
  "${ANALYZE_CONTAINERS_ROOT_DIR}/utils/scripts/build-extensions" "${extension_args[@]}"

  print_success "Extensions have been built"
}

function jq_assets_query() {
  local asset_type="$1"
  local dir_name

  case "$asset_type" in
  "configs")
    dir_name="configs"
    ;;
  "connectors")
    dir_name="connector-images"
    ;;
  "additionalResources")
    dir_name="additional-resources"
    ;;
  "extensions")
    dir_name="i2a-extensions"
    ;;
  "plugins")
    dir_name="i2a-plugins"
    ;;
  "dataSets")
    dir_name="i2a-data"
    ;;
  "gatewaySchemas")
    dir_name="gateway-schemas"
    ;;
  "backups")
    # Backups are implied by configs
    asset_type="configs"
    dir_name="backups"
    ;;
  *)
    print_error_and_exit "Unknown asset type ${asset_type}"
    ;;
  esac

  echo ".sharedConfigurations.rootDirectory as \$root | .sharedConfigurations.repositories // [] | map(.path as \$path | \
select(has(\"${asset_type}\")) | .${asset_type} | \
map(\"\(\$root)/\"+\"\(\$path)/${dir_name}/\"+.)) | .[][]"
}

function search_assets_dir_if_exists() {
  local path="$1"
  local -n array="$2"
  local tmp_array
  if [[ ! -d "${path}" ]]; then
    echo "${array[*]}"
    return
  fi
  readarray -t tmp_array < <(find "${path}" -maxdepth 1 -mindepth 1 -type d | sort)
  array+=("${tmp_array[@]}")
  echo "${array[*]}"
}

function search_assets_files_if_exists() {
  local path="$1"
  # Known shellcheck bug https://github.com/koalaman/shellcheck/issues/1309
  # shellcheck disable=SC2178
  local -n array="$2"
  local tmp_array
  if [[ ! -d "${path}" ]]; then
    echo "${array[*]}"
    return
  fi
  readarray -t tmp_array < <(find "${path}" -maxdepth 1 -mindepth 1 -type f \
    -not -name '.*' | sort)
  array+=("${tmp_array[@]}")
  echo "${array[*]}"
}

function error_if_dir_not_exists_in_array() {
  local -n array_of_dirs="$1"
  for dir in "${array_of_dirs[@]}"; do
    if [[ ! -d "${dir}" ]]; then
      print_path_not_found_and_exit "${dir}"
    fi
  done
}

function create_backup_dir_if_not_exists() {
  local -n array_of_dirs="$1"

  for dir in "${array_of_dirs[@]}"; do
    create_folder "${dir}"
  done
}

function remove_if_dir_not_exists_in_array() {
  local -n array_of_dirs="$1"
  local -a new_array
  for dir in "${array_of_dirs[@]}"; do
    if [[ -d "${dir}" ]]; then
      new_array+=("${dir}")
    fi
  done
  echo "${new_array[@]}"
}

function ensure_not_duplicated_assets() {
  local -n array_of_assets="$1"
  local local_asset_folder="$2"
  local name
  local reviewed_assets=()

  # Handle gateway schemas specially since they are files
  if [[ "$(basename "${local_asset_folder}")" == "gateway-schemas" ]]; then
    readarray -t reviewed_assets < <(find "${local_asset_folder}" -maxdepth 1 \
      -mindepth 1 -type f -not -name '.*' -exec basename {} \; | sort)
  else
    readarray -t reviewed_assets < <(find "${local_asset_folder}" -maxdepth 1 \
      -mindepth 1 -type d -exec basename {} \; | sort)
  fi
  for asset in "${array_of_assets[@]}"; do
    name=$(basename "${asset}")
    if is_string_in_array "${name}" reviewed_assets; then
      print_error_and_exit "Asset '${name}' is duplicated. Please review your \
path-configuration.json file."
    fi
    reviewed_assets+=("${name}")
  done
}

function ensure_correctly_setup_connectors() {
  local -n array_of_assets="$1"
  local name
  local reviewed_assets=()

  for asset in "${array_of_assets[@]}"; do
    if [[ ! -f "${asset}/connector-definition.json" ]]; then
      print_warn ""
    fi
  done
}

function create_symlinks() {
  local -n from_path_array="$1"
  local to_path="$2"
  local asset_name from_path asset_type

  asset_type="$(basename "${to_path}")"

  for from_path in "${from_path_array[@]}"; do
    asset_name="$(basename "${from_path}")"
    case "${asset_type}" in
    "connector-images")
      if [[ ! -f "${from_path}/connector-definition.json" ]]; then
        print_warn "Shared connector '${asset_name}' configured incorrectly. Skipping."
        continue
      fi
      ;;
    "i2a-extensions")
      no_jars="true"
      for jar_file in "${from_path}/"*.jar; do
        if [[ -f "${jar_file}" ]]; then
          # We only need to check for the existence of one
          no_jars="false"
          break
        fi
      done
      if [[ ! -f "${from_path}/pom.xml" && "${no_jars}" == "true" ]]; then
        print_warn "Shared extension '${asset_name}' configured incorrectly. Skipping."
        continue
      fi
      ;;
    esac
    ln -s "${from_path}" "${to_path}/${asset_name}"
  done
}

function print_path_not_found_and_exit() {
  local path="$1"
  print_error_and_exit "Path '${path}' cannot be found. \
Please review your path-configuration.json file."
}

function ensure_created_backup_dir_for_all_configs() {
  local -n backups="$1"
  local -n configs="$2"
  local config_name
  local -a configs_with_backups=()
  for backup in "${backups[@]}"; do
    configs_with_backups+=("$(basename "${backup}")")
  done
  for config in "${configs[@]}"; do
    config_name="$(basename "${config}")"

    if ! is_string_in_array "${config_name}" configs_with_backups; then
      backups+=("${config/"configs/${config_name}"/"backups/${config_name}"}")
    fi
  done

  # Create backup directories if they don't exist
  create_backup_dir_if_not_exists backups

  echo "${backups[@]}"
}

function run_link_task() {
  local referenced_backups referenced_connectors referenced_plugins \
    referenced_configs referenced_data_sets referenced_extensions \
    referenced_gateway_schemas referenced_all
  local root_dir tmp_array
  local path_configuration_file

  path_configuration_file="${ANALYZE_CONTAINERS_ROOT_DIR}/path-configuration.json"

  if [[ ! -f "${path_configuration_file}" ]]; then
    print_warn "File ${path_configuration_file} does not exist. Skipping."
    exit 0
  fi
  if [[ -z $(jq -r '.sharedConfigurations // empty' <"${path_configuration_file}") ]]; then
    print_warn "File ${path_configuration_file} does not contain shared configurations. Skipping."
    exit 0
  fi

  print "Update linked configurations"
  print_info "Remove all current links"
  find "${ANALYZE_CONTAINERS_ROOT_DIR}/connector-images" -type l -delete
  find "${ANALYZE_CONTAINERS_ROOT_DIR}/i2a-extensions" -type l -delete
  find "${ANALYZE_CONTAINERS_ROOT_DIR}/i2a-data" -type l -delete
  find "${ANALYZE_CONTAINERS_ROOT_DIR}/configs" -type l -delete
  find "${ANALYZE_CONTAINERS_ROOT_DIR}/i2a-plugins" -type l -delete
  find "${ANALYZE_CONTAINERS_ROOT_DIR}/backups" -type l -delete
  find "${ANALYZE_CONTAINERS_ROOT_DIR}/gateway-schemas" -type l -delete
  find "${ANALYZE_CONTAINERS_ROOT_DIR}/additional-resources" -type l -delete

  print_info "Ensure all configurations are accessible"
  # Check root is accessible
  root_dir=$(jq -r '.sharedConfigurations.rootDirectory' <"${path_configuration_file}")
  if [[ -z "${root_dir}" || ! -d "${root_dir}" ]]; then
    print_error_and_exit "The shared configuration root directory cannot be accessed. \
Ensure that the directory is specified correctly and run the configure-paths command."
  fi
  readarray -t referenced_all < <(jq -r '.sharedConfigurations.rootDirectory as $root | .sharedConfigurations.repositories // [] | 
map(.path as $path | select(has("connectors") or has("extensions") or has("additionalResources") or
has("dataSets") or has("configs") or has("plugins") or has("gatewaySchemas") | 
not) | "\($root)/" + "\($path)") | .[]' <"${path_configuration_file}")

  readarray -t referenced_connectors < <(jq -r \
    "$(jq_assets_query "connectors")"\  <"${path_configuration_file}")
  readarray -t referenced_extensions < <(jq -r \
    "$(jq_assets_query "extensions")" <"${path_configuration_file}")
  readarray -t referenced_data_sets < <(jq -r \
    "$(jq_assets_query "dataSets")" <"${path_configuration_file}")
  readarray -t referenced_configs < <(jq -r \
    "$(jq_assets_query "configs")" <"${path_configuration_file}")
  readarray -t referenced_plugins < <(jq -r \
    "$(jq_assets_query "plugins")" <"${path_configuration_file}")
  readarray -t referenced_gateway_schemas < <(jq -r \
    "$(jq_assets_query "gatewaySchemas")" <"${path_configuration_file}")
  readarray -t referenced_backups < <(jq -r \
    "$(jq_assets_query "backups")" <"${path_configuration_file}")
  readarray -t referenced_additional_resources < <(jq -r \
    "$(jq_assets_query "additionalResources")" <"${path_configuration_file}")

  # Validate existence of paths
  error_if_dir_not_exists_in_array referenced_connectors
  error_if_dir_not_exists_in_array referenced_extensions
  error_if_dir_not_exists_in_array referenced_data_sets
  error_if_dir_not_exists_in_array referenced_configs
  error_if_dir_not_exists_in_array referenced_plugins
  error_if_dir_not_exists_in_array referenced_additional_resources

  # Gateway schemas are files so ensure to append the correct endings
  local schema_names_length=${#referenced_gateway_schemas[@]}
  local tmp_schema schema_path charting_schemes_path
  for ((i = 0; i < schema_names_length; i++)); do
    tmp_schema="${referenced_gateway_schemas[$i]}"
    schema_path="${tmp_schema}-schema.xml"
    charting_schemes_path="${tmp_schema}-schema-charting-schemes.xml"
    if [[ ! -f "${schema_path}" ]]; then
      print_path_not_found_and_exit "${schema_path}"
    fi
    referenced_gateway_schemas["${i}"]="${schema_path}"
    if [[ ! -f "${charting_schemes_path}" ]]; then
      print_path_not_found_and_exit "${charting_schemes_path}"
    fi
    referenced_gateway_schemas+=("${charting_schemes_path}")
  done

  # Populate with "all" references
  for configuration_path in "${referenced_all[@]}"; do
    if [[ ! -d "${configuration_path}" ]]; then
      print_path_not_found_and_exit "${configuration_path}"
    fi
    IFS=' ' read -r -a referenced_connectors <<<"$(search_assets_dir_if_exists \
      "${configuration_path}/connector-images" referenced_connectors)"
    IFS=' ' read -r -a referenced_extensions <<<"$(search_assets_dir_if_exists \
      "${configuration_path}/i2a-extensions" referenced_extensions)"
    IFS=' ' read -r -a referenced_data_sets <<<"$(search_assets_dir_if_exists \
      "${configuration_path}/i2a-data" referenced_data_sets)"
    IFS=' ' read -r -a referenced_configs <<<"$(search_assets_dir_if_exists \
      "${configuration_path}/configs" referenced_configs)"
    IFS=' ' read -r -a referenced_plugins <<<"$(search_assets_dir_if_exists \
      "${configuration_path}/i2a-plugins" referenced_plugins)"
    IFS=' ' read -r -a referenced_backups <<<"$(search_assets_dir_if_exists \
      "${configuration_path}/backups" referenced_backups)"
    IFS=' ' read -r -a referenced_additional_resources <<<"$(search_assets_dir_if_exists \
      "${configuration_path}/additional-resources" referenced_additional_resources)"
    IFS=' ' read -r -a referenced_gateway_schemas \
      <<<"$(search_assets_files_if_exists \
        "${configuration_path}/gateway-schemas" referenced_gateway_schemas)"
  done

  # Create all required backup directories for linking
  IFS=' ' read -r -a referenced_backups <<<"$(ensure_created_backup_dir_for_all_configs referenced_backups \
    referenced_configs)"

  print_info "Ensure no duplicates"
  ensure_not_duplicated_assets referenced_connectors "${ANALYZE_CONTAINERS_ROOT_DIR}/connector-images"
  ensure_not_duplicated_assets referenced_extensions "${ANALYZE_CONTAINERS_ROOT_DIR}/i2a-extensions"
  ensure_not_duplicated_assets referenced_data_sets "${ANALYZE_CONTAINERS_ROOT_DIR}/i2a-data"
  ensure_not_duplicated_assets referenced_configs "${ANALYZE_CONTAINERS_ROOT_DIR}/configs"
  ensure_not_duplicated_assets referenced_plugins "${ANALYZE_CONTAINERS_ROOT_DIR}/i2a-plugins"
  ensure_not_duplicated_assets referenced_backups "${ANALYZE_CONTAINERS_ROOT_DIR}/backups"
  ensure_not_duplicated_assets referenced_additional_resources "${ANALYZE_CONTAINERS_ROOT_DIR}/additional-resources"
  ensure_not_duplicated_assets referenced_gateway_schemas "${ANALYZE_CONTAINERS_ROOT_DIR}/gateway-schemas"

  if [[ "${EXECUTED_WITH_ERRORS}" != "true" ]]; then
    print_info "Create symlinks"
    create_symlinks referenced_connectors "${ANALYZE_CONTAINERS_ROOT_DIR}/connector-images"
    create_symlinks referenced_extensions "${ANALYZE_CONTAINERS_ROOT_DIR}/i2a-extensions"
    create_symlinks referenced_data_sets "${ANALYZE_CONTAINERS_ROOT_DIR}/i2a-data"
    create_symlinks referenced_configs "${ANALYZE_CONTAINERS_ROOT_DIR}/configs"
    create_symlinks referenced_plugins "${ANALYZE_CONTAINERS_ROOT_DIR}/i2a-plugins"
    create_symlinks referenced_backups "${ANALYZE_CONTAINERS_ROOT_DIR}/backups"
    create_symlinks referenced_additional_resources "${ANALYZE_CONTAINERS_ROOT_DIR}/additional-resources"
    create_symlinks referenced_gateway_schemas "${ANALYZE_CONTAINERS_ROOT_DIR}/gateway-schemas"
  fi

  print_success "Shared configurations have been linked."
}

function run_task() {
  case "${TASK}" in
  backup)
    run_backup_task
    ;;
  copy)
    run_copy_task
    ;;
  upgrade)
    run_upgrade_task
    ;;
  update)
    run_update_task
    ;;
  connectors)
    run_build_connectors_task
    ;;
  extensions)
    run_build_extensions_task
    ;;
  clean)
    run_clean_task
    ;;
  stop)
    run_stop_task
    ;;
  link)
    run_link_task
    ;;
  renew-certificates)
    run_renew_certificates_task
    ;;
  esac
}

function main() {
  parse_arguments "$@"
  source_common_variables_and_scripts
  validate_arguments
  set_defaults
  check_docker_is_running
  run_task
}

main "$@"
